import os
from typing import List, Tuple

import streamlit as st
from PIL import Image
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from huggingface_hub import hf_hub_download

from model_def import build_model

# ---------------- Page ----------------
st.set_page_config(page_title="Alzheimer's MRI ‚Äî Inception v3", layout="centered")
st.title("üß† MRI-Based Classification of Alzheimer's Disease Severity (Inception v3)")

# ---------------- Config ----------------
DEVICE = "cpu"
IMAGE_SIZE = 299                     # Inception v3 ‡πÉ‡∏ä‡πâ 299x299
CLASSES_FILE = "classes.txt"

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Secrets (‡πÅ‡∏Å‡πâ‡πÉ‡∏ô Streamlit Cloud > Settings > Secrets)
HF_REPO_ID  = st.secrets.get("HF_REPO_ID",  "FatornahBk/MRI-Based-Classification-of-Alzheimer-s-Disease-Severity.git")
HF_FILENAME = st.secrets.get("HF_FILENAME", "inception_v3_checkpoint_fold0.pt")

@st.cache_resource(show_spinner=True)
def load_model_and_classes():
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏≤‡∏™
    with open(CLASSES_FILE, "r", encoding="utf-8") as f:
        classes = [ln.strip() for ln in f if ln.strip()]
    num_classes = len(classes)

    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î checkpoint ‡∏à‡∏≤‡∏Å HF (cache ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå)
    weights_path = hf_hub_download(repo_id=HF_REPO_ID, filename=HF_FILENAME)

    model = build_model(num_classes=num_classes, device=DEVICE)

    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á plain state_dict ‡πÅ‡∏•‡∏∞ checkpoint dict + ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ torch 2.6 (weights_only=True)
    try:
        sd = torch.load(weights_path, map_location=DEVICE)  # ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô weights_only=True ‡∏ï‡∏≤‡∏°‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå
    except Exception:
        sd = torch.load(weights_path, map_location=DEVICE, weights_only=False)

    if isinstance(sd, dict) and "state_dict" in sd:
        sd = sd["state_dict"]

    # ‡∏•‡∏≠‡∏Å prefix ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å lightning/ddp ‡∏≠‡∏≠‡∏Å
    fixed = {}
    for k, v in sd.items():
        nk = k
        for prefix in ("model.", "module.", "net."):
            if nk.startswith(prefix):
                nk = nk[len(prefix):]
        fixed[nk] = v

    missing, unexpected = model.load_state_dict(fixed, strict=False)
    if missing:  # debug log ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•
        print("Missing keys:", missing)
    if unexpected:
        print("Unexpected keys:", unexpected)

    model.eval()
    return model, classes

@st.cache_resource
def get_transform():
    # Inception v3 ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ä‡πâ Normalization ‡∏ï‡∏≤‡∏° ImageNet
    return T.Compose([
        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        T.ToTensor(),
        T.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
    ])

def predict(img: Image.Image, model: torch.nn.Module, classes: List[str]) -> List[Tuple[str, float]]:
    x = get_transform()(img.convert("RGB")).unsqueeze(0)  # [1,3,299,299]
    with torch.no_grad():
        logits = model(x.to(DEVICE))
        probs = F.softmax(logits, dim=1).cpu().numpy().flatten()
    return list(zip(classes, probs))

# ---------------- UI ----------------
uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û (jpg/png/webp)", type=["jpg", "jpeg", "png", "webp"])
col1, col2 = st.columns(2)

if uploaded:
    img = Image.open(uploaded)
    col1.image(img, caption="Input", use_container_width=True)

    if st.button("üîÆ Predict"):
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢..."):
            model, classes = load_model_and_classes()
            results = predict(img, model, classes)

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡πÅ‡∏™‡∏î‡∏á (‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° classes.txt ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ô‡∏µ‡πâ)
        preferred_order = ["Mild Impairment", "Moderate Impairment", "No Impairment", "Very Mild Impairment"]
        rank = {n: i for i, n in enumerate(preferred_order)}
        results_sorted = sorted(results, key=lambda x: rank.get(x[0], 999))

        with col2:
            st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
            for cls, p in results_sorted:
                st.write(f"**{cls}** : {p*100:.2f}%")
            top_cls, top_p = max(results, key=lambda x: x[1])
            st.success(f"Predict: **{top_cls}** ({top_p*100:.2f}%)")
else:
    st.info("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û MRI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")