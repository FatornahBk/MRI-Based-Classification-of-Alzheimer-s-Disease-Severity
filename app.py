# app.py
import os
import io
import importlib
from collections import OrderedDict

import streamlit as st
from PIL import Image
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from timm import create_model

# ----- (Optional) ‡πÉ‡∏ä‡πâ HF ‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ -----
try:
    from huggingface_hub import hf_hub_download
    _HAS_HF = True
except Exception:
    _HAS_HF = False


# =========================
# Page / Defaults
# =========================
st.set_page_config(page_title="MRI-based Classification (EfficientNet-B7)", layout="centered")

DEVICE      = "cpu"
IMAGE_SIZE  = 600
CLASSES_TXT = "classes.txt"
WEIGHTS_DIR = "weights"
os.makedirs(WEIGHTS_DIR, exist_ok=True)

# =========================
# Read Secrets/ENV (‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà Secrets ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î)
# =========================
def _get_secret_env(key, default=None):
    # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å Streamlit Secrets ‡∏Å‡πà‡∏≠‡∏ô ‚Üí ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá‡πÑ‡∏õ ENV
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key, default)

HF_REPO_ID   = _get_secret_env("HF_REPO_ID",   "")   # e.g. "FatornahBk/ad-severity-weights"
HF_FILENAME  = _get_secret_env("HF_FILENAME",  "")   # e.g. "efficientnet_b7_state_dict.pt"
HF_REPO_TYPE = _get_secret_env("HF_REPO_TYPE", "model")  # or "dataset"
HF_TOKEN     = _get_secret_env("HF_TOKEN",     None)

# ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ HF ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡πâ‡∏á MODEL_URL ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á (public)
MODEL_URL    = _get_secret_env("MODEL_URL",    "")   # e.g. "https://.../efficientnet_b7_state_dict.pt"

# ‡∏û‡∏≤‡∏ò‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏° HF_FILENAME ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å URL)
CKPT_LOCAL   = os.path.join(WEIGHTS_DIR, HF_FILENAME or os.path.basename(MODEL_URL) or "model.pt")


# =========================
# Utils
# =========================
def load_classes():
    if os.path.exists(CLASSES_TXT):
        with open(CLASSES_TXT, "r", encoding="utf-8") as f:
            classes = [line.strip() for line in f if line.strip()]
        if classes:
            return classes
    return [f"Class {i}" for i in range(2)]  # fallback

def _download_via_hf(repo_id, filename, repo_type, token) -> str:
    if not _HAS_HF:
        raise RuntimeError("huggingface_hub ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô environment (‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô requirements.txt).")
    return hf_hub_download(
        repo_id=repo_id,
        filename=filename,
        repo_type=repo_type,
        token=token,
        local_dir=WEIGHTS_DIR,
        local_dir_use_symlinks=False,
        cache_dir=None,
    )

def _download_via_url(url, out_path):
    import urllib.request
    req = urllib.request.Request(url)
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô private ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ header token (‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©)
    if HF_TOKEN and "huggingface.co" in url:
        req.add_header("Authorization", f"Bearer {HF_TOKEN}")
    with urllib.request.urlopen(req) as resp, open(out_path, "wb") as f:
        f.write(resp.read())
    return out_path

def ensure_weights_exist() -> str:
    """
    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å 2 ‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
      1) Hugging Face: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ HF_REPO_ID + HF_FILENAME (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö private ‡∏î‡πâ‡∏ß‡∏¢ HF_TOKEN)
      2) URL ‡∏ï‡∏£‡∏á: ‡∏ï‡∏±‡πâ‡∏á MODEL_URL ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå public (‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Bearer ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô HF+token)
    ‡∏Ñ‡∏∑‡∏ô path ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
    """
    # ‡πÉ‡∏ä‡πâ Hugging Face ‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡∏Ñ‡∏£‡∏ö
    if HF_REPO_ID and HF_FILENAME:
        st.write("‚¨áÔ∏è Downloading weights from Hugging Face‚Ä¶")
        local_path = _download_via_hf(HF_REPO_ID, HF_FILENAME, HF_REPO_TYPE, HF_TOKEN)
    elif MODEL_URL:
        st.write("‚¨áÔ∏è Downloading weights from direct URL‚Ä¶")
        local_path = _download_via_url(MODEL_URL, CKPT_LOCAL)
    else:
        raise RuntimeError(
            "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n"
            "- ‡∏ï‡∏±‡πâ‡∏á Secrets/ENV: HF_REPO_ID + HF_FILENAME (‡πÅ‡∏•‡∏∞ HF_TOKEN ‡∏ñ‡πâ‡∏≤ private) "
            "‡∏´‡∏£‡∏∑‡∏≠\n- ‡∏ï‡∏±‡πâ‡∏á MODEL_URL ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"
        )

    # ‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏î‡πâ pointer/‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
    if not os.path.exists(local_path) or os.path.getsize(local_path) < 10_000:
        raise RuntimeError(
            "Weight file ‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥). "
            "‡∏ï‡∏£‡∏ß‡∏à repo/‡πÑ‡∏ü‡∏•‡πå ‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
        )
    return local_path

def _torch_supports_weights_only() -> bool:
    import inspect
    return "weights_only" in inspect.signature(torch.load).parameters

def _allow_safe_globals():
    """allowlist ‡∏Ñ‡∏•‡∏≤‡∏™‡∏¢‡∏≠‡∏î‡∏Æ‡∏¥‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢ Lightning/Fabric"""
    try:
        from torch.serialization import add_safe_globals
    except Exception:
        return
    safe = []
    try:
        mod = importlib.import_module("lightning.fabric.wrappers")
        if hasattr(mod, "_FabricModule"):
            safe.append(getattr(mod, "_FabricModule"))
    except Exception:
        pass
    try:
        mod = importlib.import_module("pytorch_lightning.core.module")
        if hasattr(mod, "LightningModule"):
            safe.append(getattr(mod, "LightningModule"))
    except Exception:
        pass
    if safe:
        try:
            add_safe_globals(safe)
        except Exception:
            pass

def _load_checkpoint_safely(path: str):
    """
    ‡∏Ñ‡∏∑‡∏ô (state_dict, how)
    Strategy:
      1) torch.load(weights_only=True) ‡∏ñ‡πâ‡∏≤‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
      2) allow safe globals ‚Üí torch.load ‡∏õ‡∏Å‡∏ï‡∏¥ ‚Üí ‡∏î‡∏∂‡∏á state_dict ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°
      3) ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí .state_dict()
    """
    # 1) weights_only
    if _torch_supports_weights_only():
        try:
            obj = torch.load(path, map_location="cpu", weights_only=True)
            if isinstance(obj, dict):
                for k in ("state_dict", "model", "net", "weights"):
                    if k in obj and isinstance(obj[k], dict):
                        return obj[k], f"weights_only:{k}"
                return obj, "weights_only:raw_dict"
        except Exception:
            pass

    # 2) pickle ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
    _allow_safe_globals()
    try:
        obj = torch.load(path, map_location="cpu")
        if isinstance(obj, dict):
            if "state_dict" in obj and isinstance(obj["state_dict"], dict):
                return obj["state_dict"], "pickle:state_dict"
            for k in ("model", "net", "weights"):
                if k in obj and isinstance(obj[k], dict):
                    return obj[k], f"pickle:{k}"
            return obj, "pickle:raw_dict"
        if hasattr(obj, "state_dict"):
            return obj.state_dict(), "object.state_dict"
    except ModuleNotFoundError as e:
        st.error(
            f"Missing dependency while unpickling checkpoint: {e}. "
            "‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡∏à‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô requirements.txt ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô pure state_dict"
        )
        raise
    return None, "failed"

def _fix_state_dict_keys(sd: dict):
    """‡∏•‡∏ö prefix 'module.' / 'model.' ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå"""
    new_sd = OrderedDict()
    for k, v in sd.items():
        nk = k
        if nk.startswith("module."): nk = nk[7:]
        if nk.startswith("model."):  nk = nk[6:]
        new_sd[nk] = v
    return new_sd


# =========================
# Build / Load model (cached)
# =========================
@st.cache_resource(show_spinner=True)
def get_model_and_classes():
    # 1) ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
    ckpt_path = ensure_weights_exist()

    # 2) ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏≤‡∏™
    classes = load_classes()
    num_classes = len(classes)

    # 3) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (EfficientNet-B7)
    model = create_model("tf_efficientnet_b7_ns", pretrained=False, num_classes=num_classes)
    model.to(DEVICE)

    # 4) ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Å‡∏û‡∏≠‡∏¢‡∏ï‡πå
    sd, how = _load_checkpoint_safely(ckpt_path)
    if sd is None:
        raise RuntimeError("‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Å‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô pure state_dict ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á dev ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà")

    sd = _fix_state_dict_keys(sd)

    # 5) ‡πÉ‡∏™‡πà‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
    missing, unexpected = model.load_state_dict(sd, strict=False)
    if missing:
        st.warning(f"Missing keys: {list(missing)[:5]}{' ...' if len(missing)>5 else ''}")
    if unexpected:
        st.warning(f"Unexpected keys: {list(unexpected)[:5]}{' ...' if len(unexpected)>5 else ''}")

    model.eval()
    return model, classes


# =========================
# Inference utils
# =========================
def get_transform():
    return T.Compose([
        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        T.ToTensor(),
        T.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
    ])

@torch.inference_mode()
def predict_image(model, classes, image: Image.Image, topk=3):
    x = get_transform()(image.convert("RGB")).unsqueeze(0).to(DEVICE)
    logits = model(x)
    probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    top_idx = probs.argsort()[::-1][:min(topk, len(classes))]
    return [(classes[i], float(probs[i])) for i in top_idx]


# =========================
# UI
# =========================
st.title("üß† MRI-based Classification (EfficientNet-B7)")

with st.expander("‚ÑπÔ∏è Setup tips", expanded=False):
    st.markdown(
        "- ‡∏ï‡∏±‡πâ‡∏á Secrets/ENV ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏ó‡∏≤‡∏á:\n"
        "  - **HF_REPO_ID + HF_FILENAME** (+ HF_TOKEN ‡∏ñ‡πâ‡∏≤ private) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Hugging Face\n"
        "  - ‡∏´‡∏£‡∏∑‡∏≠ **MODEL_URL** ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (public)\n"
        "- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô private Hugging Face ‡πÉ‡∏™‡πà `HF_TOKEN` ‡πÉ‡∏ô Secrets ‡∏î‡πâ‡∏ß‡∏¢\n"
        "- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô **pure state_dict** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á dependency ‡πÅ‡∏õ‡∏•‡∏Å ‡πÜ"
    )

try:
    model, classes = get_model_and_classes()
    st.success(f"Model loaded ‚úÖ | Classes = {len(classes)}")
except Exception as e:
    st.error(f"Failed to load model: {e}")
    st.stop()

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û (JPG/PNG)", type=["jpg", "jpeg", "png"])
if uploaded:
    from PIL import Image
    img = Image.open(io.BytesIO(uploaded.read()))
    st.image(img, caption="Input image", use_container_width=True)

    with st.spinner("Predicting..."):
        results = predict_image(model, classes, img, topk=3)
    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
    for label, prob in results:
        st.write(f"- **{label}** : {prob:.4f}")
else:
    st.info("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")