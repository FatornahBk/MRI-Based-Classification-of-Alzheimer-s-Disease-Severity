import os
import streamlit as st
from PIL import Image
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from timm import create_model

# ---------------- CONFIG ----------------
DEVICE = "cpu"
IMAGE_SIZE = 600
CLASSES_TXT = "classes.txt"
WEIGHTS_DIR = "weights"
WEIGHTS_FILE = "weights/efficientnet_b7_fold1_state_dict.pt"

# ‡∏ï‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà weights_only=False ‡πÅ‡∏•‡πâ‡∏ß)
sd = torch.load(WEIGHTS_FILE, map_location=DEVICE)  # 2.6 ‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå weights_only=True ‡πÇ‡∏≠‡πÄ‡∏Ñ
model.load_state_dict(sd, strict=False)   # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß
MODEL_NAME = "tf_efficientnet_b7_ns (fold1)"

# ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÇ‡∏ä‡∏ß‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)
TARGET_ORDER = [
    "Mild Impairment",
    "Moderate Impairment",
    "No Impairment",
    "Very Mild Impairment",
]

# ---------------- LOAD CLASSES ----------------
@st.cache_resource(show_spinner=False)
def load_class_names(path):
    with open(path, "r", encoding="utf-8") as f:
        return [ln.strip() for ln in f if ln.strip()]

# ---------------- MODEL ----------------
@st.cache_resource(show_spinner=False)
def load_model(weights_path, num_classes):
    model = create_model("tf_efficientnet_b7_ns", pretrained=False, num_classes=num_classes)
    model.to(DEVICE)
    # ‡πÇ‡∏´‡∏•‡∏î state_dict ‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    sd = torch.load(weights_path, map_location=DEVICE)
    missing, unexpected = model.load_state_dict(sd, strict=False)
    if missing or unexpected:
        st.info(f"Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")
    model.eval()
    return model

# ---------------- TRANSFORM ----------------
@st.cache_resource(show_spinner=False)
def get_transform():
    return T.Compose([
        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
    ])

def predict_full(model, img, class_names):
    """‡∏Ñ‡∏∑‡∏ô dict {class_name: prob_float} ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™"""
    tfm = get_transform()
    x = tfm(img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        logits = model(x)
        probs = F.softmax(logits, dim=1)[0].cpu().numpy().tolist()
    # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏Å‡∏±‡∏ö prob
    out = {cls: float(p) for cls, p in zip(class_names, probs)}
    return out

# ---------------- UI ----------------
st.set_page_config(page_title="MRI-based Classification (EfficientNet-B7)")
st.title("MRI-Based Classification of Alzheimer's Disease Severity")
st.caption(f"Model: **{MODEL_NAME}**")

# ‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™ + ‡πÄ‡∏ä‡πá‡∏Ñ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
class_names = load_class_names(CLASSES_TXT)
weights_path = os.path.join(WEIGHTS_DIR, WEIGHTS_FILE)
if not os.path.exists(weights_path):
    st.error(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å {weights_path}")
    st.stop()

# ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô/‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö TARGET_ORDER
if len(class_names) != len(TARGET_ORDER):
    st.warning(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏ô classes.txt ({len(class_names)}) ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö TARGET_ORDER ({len(TARGET_ORDER)})")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏•‡πá‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô
norm = lambda s: " ".join(s.split()).strip().lower()
class_names_norm = {norm(c): c for c in class_names}
target_norm = [norm(t) for t in TARGET_ORDER]
missing_in_model = [t for t in target_norm if t not in class_names_norm]
if missing_in_model:
    st.warning("‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏ô TARGET_ORDER ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô classes.txt: " +
               ", ".join([TARGET_ORDER[target_norm.index(m)] for m in missing_in_model]))

model = load_model(weights_path, num_classes=len(class_names))

# ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ/‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô session_state
if "uploaded_img" not in st.session_state:
    st.session_state.uploaded_img = None
if "dist" not in st.session_state:
    st.session_state.dist = None

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û (JPG/PNG)", type=["jpg", "jpeg", "png"])
if uploaded:
    st.session_state.uploaded_img = Image.open(uploaded).convert("RGB")
    st.image(st.session_state.uploaded_img, caption="‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î", use_column_width=True)
    st.session_state.dist = None  # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ú‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÉ‡∏´‡∏°‡πà

# ‡∏õ‡∏∏‡πà‡∏° Predict
btn = st.button("üîÆ Predict", type="primary", disabled=st.session_state.uploaded_img is None)
if btn and st.session_state.uploaded_img is not None:
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå..."):
        full_dist = predict_full(model, st.session_state.uploaded_img, class_names)
        st.session_state.dist = full_dist

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå "‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™" ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
if st.session_state.dist:
    st.subheader("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡∏≤‡∏° TARGET_ORDER
    for t_name in TARGET_ORDER:
        key = norm(t_name)
        # ‡∏´‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô TARGET_ORDER ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö classes.txt ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πä‡∏∞ ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÅ‡∏ö‡∏ö normalize
        if key in class_names_norm:
            actual_name = class_names_norm[key]
            p = st.session_state.dist.get(actual_name, 0.0)
        else:
            # ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí ‡πÇ‡∏ä‡∏ß‡πå 0% ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏•‡πâ‡∏ß
            p = 0.0
        st.markdown(f"- **{t_name}**: {p*100:.2f}%")
        st.progress(min(max(p, 0.0), 1.0))

    # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πà‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Top-1)
    top_class = max(st.session_state.dist.items(), key=lambda kv: kv[1])
