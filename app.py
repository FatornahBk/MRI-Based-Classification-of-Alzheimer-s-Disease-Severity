# app.py
import os
import io
import urllib.request
import importlib
from collections import OrderedDict

import streamlit as st
from PIL import Image
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from timm import create_model


# =========================
# Configs
# =========================
st.set_page_config(page_title="MRI-based Classification (EfficientNet-B7)", layout="centered")

MODEL_URL  = "https://huggingface.co/your-org/weights/resolve/main/efficientnet_b7_state_dict.pt"
WEIGHTS_DIR = "weights"
CKPT_PATH  = os.path.join(WEIGHTS_DIR, "efficientnet_b7_state_dict.pt")

CLASSES_TXT = "classes.txt"   # ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
IMAGE_SIZE  = 600             # tf_efficientnet_b7_ns ‡πÉ‡∏ä‡πâ 600x600
DEVICE      = "cpu"           # ‡πÉ‡∏ä‡πâ CPU ‡∏ö‡∏ô Streamlit Cloud


# =========================
# Utils
# =========================
def ensure_weights_exist():
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏õ‡πá‡∏ô LFS pointer)"""
    os.makedirs(WEIGHTS_DIR, exist_ok=True)
    if (not os.path.exists(CKPT_PATH)) or (os.path.getsize(CKPT_PATH) < 10_000):
        st.write("‚¨áÔ∏è Downloading model weights...")
        urllib.request.urlretrieve(MODEL_URL, CKPT_PATH)
    # ‡∏Å‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
    if os.path.getsize(CKPT_PATH) < 10_000:
        raise RuntimeError("Downloaded weight file looks invalid (too small). Check MODEL_URL or hosting permissions.")


def _torch_supports_weights_only() -> bool:
    import inspect
    return "weights_only" in inspect.signature(torch.load).parameters


def _allow_safe_globals():
    """‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï safe globals ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏ü‡∏à‡∏≤‡∏Å Lightning/Fabric"""
    try:
        from torch.serialization import add_safe_globals
    except Exception:
        return
    safe = []
    try:
        mod = importlib.import_module("lightning.fabric.wrappers")
        if hasattr(mod, "_FabricModule"):
            safe.append(getattr(mod, "_FabricModule"))
    except Exception:
        pass
    try:
        mod = importlib.import_module("pytorch_lightning.core.module")
        if hasattr(mod, "LightningModule"):
            safe.append(getattr(mod, "LightningModule"))
    except Exception:
        pass
    if safe:
        try:
            add_safe_globals(safe)
        except Exception:
            pass


def _load_checkpoint_safely(path: str):
    """
    ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ state_dict
    Strategy:
      1) weights_only=True (‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ)
      2) allow safe globals ‡πÅ‡∏•‡πâ‡∏ß torch.load ‡∏õ‡∏Å‡∏ï‡∏¥ ‚Üí ‡∏î‡∏∂‡∏á state_dict ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°
      3) ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡πá‡∏Å‡∏ï‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí ‡∏î‡∏∂‡∏á .state_dict()
    """
    # 1) weights_only=True (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô PyTorch)
    if _torch_supports_weights_only():
        try:
            obj = torch.load(path, map_location="cpu", weights_only=True)
            if isinstance(obj, dict) and any(k in obj for k in ("state_dict", "model", "net", "weights")):
                for k in ("state_dict", "model", "net", "weights"):
                    if k in obj and isinstance(obj[k], dict):
                        return obj[k], "weights_only:" + k
            if isinstance(obj, dict):
                return obj, "weights_only:raw_dict"
        except Exception:
            pass

    # 2) allow safe globals ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
    _allow_safe_globals()
    try:
        obj = torch.load(path, map_location="cpu")
        if isinstance(obj, dict):
            if "state_dict" in obj and isinstance(obj["state_dict"], dict):
                return obj["state_dict"], "pickle:state_dict"
            for k in ("model", "net", "weights"):
                if k in obj and isinstance(obj[k], dict):
                    return obj[k], f"pickle:{k}"
            # ‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô dict ‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏£‡∏á ‡πÜ
            return obj, "pickle:raw_dict"
        if hasattr(obj, "state_dict"):
            return obj.state_dict(), "object.state_dict"
    except ModuleNotFoundError as e:
        st.error(f"Missing dependency while unpickling checkpoint: {e}. "
                 f"Add the missing package to requirements.txt or re-save as pure state_dict.")
        raise
    return None, "failed"


def _fix_state_dict_keys(sd: dict):
    """‡∏•‡∏ö prefix ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢ ('module.', 'model.') ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå‡∏Ç‡∏≠‡∏á state_dict"""
    new_sd = OrderedDict()
    for k, v in sd.items():
        nk = k
        if nk.startswith("module."):
            nk = nk[len("module."):]
        if nk.startswith("model."):
            nk = nk[len("model."):]
        new_sd[nk] = v
    return new_sd


def load_classes():
    if os.path.exists(CLASSES_TXT):
        with open(CLASSES_TXT, "r", encoding="utf-8") as f:
            classes = [line.strip() for line in f if line.strip()]
        if classes:
            return classes
    # fallback
    return [f"Class {i}" for i in range(2)]  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì


# =========================
# Model loader (cached)
# =========================
@st.cache_resource(show_spinner=True)
def get_model_and_classes():
    ensure_weights_exist()

    # 1) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° (num_classes ‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å classes.txt)
    classes = load_classes()
    num_classes = len(classes)

    # tf_efficientnet_b7_ns = EfficientNet-B7 (Noisy Student)
    model = create_model("tf_efficientnet_b7_ns", pretrained=False, num_classes=num_classes)
    model.to(DEVICE)

    # 2) ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‚Üí state_dict
    sd, how = _load_checkpoint_safely(CKPT_PATH)
    if sd is None:
        raise RuntimeError("Cannot load checkpoint safely. Consider re-saving as pure state_dict (only weights).")

    sd = _fix_state_dict_keys(sd)

    # 3) ‡πÇ‡∏´‡∏•‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå (allow missing/unexpected ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ)
    missing, unexpected = model.load_state_dict(sd, strict=False)
    if missing:
        st.warning(f"Missing keys in state_dict: {list(missing)[:5]}{'...' if len(missing)>5 else ''}")
    if unexpected:
        st.warning(f"Unexpected keys in state_dict: {list(unexpected)[:5]}{'...' if len(unexpected)>5 else ''}")

    model.eval()
    return model, classes


# =========================
# Preprocessing & Inference
# =========================
def get_transform():
    return T.Compose([
        T.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        T.ToTensor(),
        # EfficientNet expects float32 in [0,1]; timm model has own norm inside in many cases,
        # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á normalize ‡πÄ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ mean/std ‡∏Ç‡∏≠‡∏á ImageNet:
        T.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
    ])

@torch.inference_mode()
def predict_image(model, classes, image: Image.Image, topk=3):
    tfm = get_transform()
    x = tfm(image.convert("RGB")).unsqueeze(0).to(DEVICE)  # (1,3,H,W)
    logits = model(x)
    probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    top_idx = probs.argsort()[::-1][:topk]
    return [(classes[i], float(probs[i])) for i in top_idx]


# =========================
# Streamlit UI
# =========================
st.title("üß† MRI-based Classification (EfficientNet-B7)")

with st.expander("‚ÑπÔ∏è Notes", expanded=False):
    st.markdown(
        "- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å URL ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LFS pointer ‡∏ö‡∏ô GitHub)\n"
        "- ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à `requirements.txt` ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÅ‡∏û‡πá‡∏Å‡πÄ‡∏Å‡∏à‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏ö ‡πÄ‡∏ä‡πà‡∏ô `timm`, `torch`, `lightning` (‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ)\n"
        "- ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡∏à‡∏≤‡∏Å Lightning/Fabric ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏∞ allowlist ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÉ‡∏´‡πâ"
    )

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (cached)
try:
    model, classes = get_model_and_classes()
    st.success(f"Model loaded. Classes = {len(classes)}")
except Exception as e:
    st.error(f"Failed to load model: {e}")
    st.stop()

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û (JPG/PNG)", type=["jpg", "jpeg", "png"])

if uploaded:
    img = Image.open(io.BytesIO(uploaded.read()))
    st.image(img, caption="Input image", use_container_width=True)

    with st.spinner("Predicting..."):
        results = predict_image(model, classes, img, topk=min(3, len(classes)))
    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
    for label, prob in results:
        st.write(f"- **{label}** : {prob:.4f}")
else:
    st.info("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")